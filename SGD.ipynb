{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "\n",
    "## 1. Loading (the boston data from the scikit learn), Splitting and Standardizing the data\n",
    "\n",
    "## 2. Custom SGD Regressor implementation (I)\n",
    "\n",
    "## 3. Scikit learn SGD Regressor implementation (II)\n",
    "\n",
    "## 4. Comparing both 2nd and 3rd implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading (the boston data from the scikit learn), Splitting and Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape (506, 13)\n",
      "shape of Y :  (506,)\n",
      "****************************************************************************************************\n",
      "Dataset \n",
      "\n",
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n",
      "****************************************************************************************************\n",
      "Target- price \n",
      "\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "boston = load_boston()\n",
    "\n",
    "bos = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "bos['price'] = boston.target\n",
    "X = bos.drop('price', axis = 1)\n",
    "Y = bos['price']\n",
    "\n",
    "print('X\\'s shape', X.shape)\n",
    "print('shape of Y : ', Y.shape)\n",
    "\n",
    "print('*'*100)\n",
    "print('Dataset \\n')\n",
    "print(X.head())\n",
    "\n",
    "print('*'*100)\n",
    "print('Target- price \\n')\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(bos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isinf(bos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "X_train, X_test , Y_train, Y_test = train_test_split(X,Y, test_size = 0.3)\n",
    "\n",
    "# standardizing the data\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Adding price column in the data\n",
    "train_data = pd.DataFrame(X_train)\n",
    "train_data['price'] = Y_train\n",
    "\n",
    "y_train = np.array(Y_train)\n",
    "y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom SGD Regressor implementation (I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MY try out !\n",
    "w = np.zeros((1, X_train.shape[1] - 1))\n",
    "w.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function for sgd\n",
    "def customsgd(train_data,k,n_iter,learning_rate,divideby ):\n",
    "    \n",
    "    # initially we will keep out w and k , 0 as per the training data\n",
    "    w = np.zeros((1, train_data.shape[1] - 1)) # doubt with the size \n",
    "    b = 0\n",
    "\n",
    "    curr_iter = 1\n",
    "    \n",
    "    while(curr_iter <= n_iter):\n",
    "        \n",
    "        # sampling the data of size k\n",
    "        temp = train_data.sample(k)\n",
    "\n",
    "        # assigning the x and y according to the k\n",
    "        x = np.array(temp.drop('price', axis = 1))\n",
    "        y = np.array(temp['price'])\n",
    "            \n",
    "            \n",
    "        # initially assigning the gradient descent as 0\n",
    "        w_gradient = np.zeros((1, train_data.shape[1] -1))\n",
    "        b_gradient = 0\n",
    "        \n",
    "        for i in range(k):\n",
    "            prediction = np.dot(w,x[i])+ b\n",
    "            w_gradient = w_gradient + (-2)*x[i]*(y[i] - prediction)\n",
    "            b_gradient = b_gradient + (-2)*(y[i] - prediction)\n",
    "        \n",
    "        # updating the w(weight) and intercept(b)\n",
    "        w = w - learning_rate * w_gradient/k\n",
    "        b = b - learning_rate * b_gradient/k\n",
    "        \n",
    "        # Dividing learning rate by specific number\n",
    "        learning_rate = learning_rate/divideby\n",
    "        \n",
    "        #incrementing the curr_iter\n",
    "        curr_iter = curr_iter + 1\n",
    "        \n",
    "    return w, b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Prediction\n",
    "def prediction(x,w,b):\n",
    "    pred = []\n",
    "    for i in range(len(x)):\n",
    "        pred_i = np.asscalar(np.dot(w,x[i]) + b)\n",
    "        pred.append(pred_i)\n",
    "    return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's use our custom sgd with parameters:\n",
    "\n",
    "## 1. learning rate = 1\n",
    "\n",
    "## 2. divideby = 2\n",
    "\n",
    "## 3. k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d57dfa9a031d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean Square Error : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[0;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 252\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "w,b = customsgd(train_data,k = 10, n_iter = 100, learning_rate = 1, divideby = 2)\n",
    "\n",
    "predict = prediction(X_test,w,b)\n",
    "\n",
    "print('Mean Square Error : ', mean_squared_error(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = customsgd(train_data,k = 1, n_iter = 10000, learning_rate = 1, divideby = 2)\n",
    "\n",
    "predict = prediction(X_test,w,b)\n",
    "\n",
    "plt.scatter(Y_test,predict)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('Scatter plot from actual y and predicted y')\n",
    "\n",
    "print('Mean Square Error : ', mean_squared_error(predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# divideby = 1 (mean's not dividing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best parameter's till now\n",
    "w,b = customsgd(train_data,k = 10, n_iter = 100, learning_rate = 0.001, divideby = 1)\n",
    "\n",
    "predict = prediction(X_test,w,b)\n",
    "\n",
    "plt.scatter(Y_test, predict)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('Scatter plot from actual y and predicted y')\n",
    "\n",
    "print('Mean Square Error : ', mean_squared_error(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = customsgd(train_data,k = 10, n_iter = 1000, learning_rate = 0.01, divideby = 1)\n",
    "\n",
    "predict = prediction(X_test,w,b)\n",
    "\n",
    "plt.scatter(Y_test, predict)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('Scatter plot from actual y and predicted y')\n",
    "\n",
    "print('Mean Square Error : ', mean_squared_error(predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scikit learn SGD Regressor implementation (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = SGDRegressor()\n",
    "clf.fit(X_train, Y_train)\n",
    "pred_sklearn = clf.predict(X_test)\n",
    "\n",
    "plt.scatter(Y_test, pred_sklearn)\n",
    "plt.grid()\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.title('Scatter plot from actual y and predicted y')\n",
    "\n",
    "print('Mean Square Error : ', mean_squared_error(pred_sklearn, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comparing both 2nd and 3rd implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating the table using PrettyTable library\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Initializing prettytable\n",
    "preety_table = PrettyTable()\n",
    "\n",
    "preety_table.field_names = [\"SGD Type\",\"Mean Squared Error\"]\n",
    "preety_table.add_row([\"Custom SGD\",MSE_CUSTOM])\n",
    "preety_table.add_row([\"Sklearn SGD\",MSE_SKLEARN])\n",
    "\n",
    "\n",
    "print(preety_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. my model is performing better than sklearn, idk how the hell is this even possible!\n",
    "# 2. SKlearn prediction's is quite different from my custom model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
